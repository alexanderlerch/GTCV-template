
@book{book_2018,
	address = {Hoboken, NJ},
	title = {book title},
	isbn = {978-1-1182-6682-3},
	publisher = {Wiley-{IEEE} Press},
	author = {Author, Author},
	year = {2018},
}

@incollection{chapter_2018,
	series = {Series},
	title = {Title},
	isbn = {978–3–89007–699–7},
	number = {5},
	booktitle = {Book Title},
	publisher = {Laaber},
	author = {Author, Author},
	editor = {Editor, Editor},
	year = {2018}
}

@book{edited_2018,
	address = {Atlanta},
	title = {Proceedings title},
	isbn = {978-0-692-61973-5},
	editor = {Editor, Editor},
	year = {2018}
}

@article{journal_2018,
	title = {Title},
	volume = {40},
	doi = {10.1080/09298215.2010.529917},
	number = {1},
	journal = {Journal},
	author = {Author, \mark Author},
	year = {2018},
	pages = {27--41},
}

@inproceedings{refpaper_2018,
	address = {Laguna Hills},
	title = {Title},
	booktitle = {Proceedings of the {International} {Conference} },
	publisher = {IEEE},
	author = {Author, Author},
	year = {2018}
}

@inproceedings{paper_2018,
	address = {Laguna Hills},
	title = {Title},
	booktitle = {Proceedings of the {International} {Conference} },
	publisher = {IEEE},
	author = {Author, Author},
	year = {2018}
}

@article{submittedjournal_2018,
	title = {Title},
	volume = {40},
	doi = {10.1080/09298215.2010.529917},
	number = {1},
	journal = {Journal},
	author = {Author, Author},
	year = {2018},
	pages = {27--41},
}

@inproceedings{burred_hierarchical_2003,
	address = {London, {UK}},
	title = {A Hierarchical Approach to Automatic Musical Genre Classification},
	url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.2.6582},
	doi = {10.1.1.2.6582},
	abstract = {A system for the automatic classification of audio signals according to audio category is presented. The signals are recognized as speech, background noise and one of 13 musical genres. A large number of audio features are evaluated for their suitability in such a classification task, including well-known physical and perceptual features, audio descriptors defined in the {MPEG}-7 standard, as well as new features proposed in this work. These are selected with regard to their ability to distinguish between a given set of audio types and to their robustness to noise and bandwidth changes. In contrast to previous systems, the feature selection and the classification process itself are carried out in a hierarchical way. This is motivated by the numerous advantages of such a tree-like structure, which include easy expansion capabilities, flexibility in the design of genre-dependent features and the ability to reduce the probability of costly errors. The resulting application is evaluated with respect to classification accuracy and computational costs.},
	booktitle = {Proceedings of the 6th International Conference on Digital Audio Effects ({DAFX})},
	author = {\textbf{Burred}, \textbf{Juan José} and Lerch, Alexander},
	year = {2003},
	file = {2003 - Burred, Lerch - A Hierarchical Approach to Automatic Musical Genre Classification.pdf:H\:\\Docs\\zotero\\storage\\EXU2F4V2\\2003 - Burred, Lerch - A Hierarchical Approach to Automatic Musical Genre Classification.pdf:application/pdf}
}

@inproceedings{kraft_tonalness_2013,
	address = {Maynooth, {UK}},
	title = {The Tonalness Spectrum: Feature-Based Estimation of tonal components},
	url = {http://www.researchgate.net/publication/256460238\_The\_tonalness\_spectrum\_feature-based\_estimation\_of\_tonal\_components/file/60b7d522d6cf67fca7.pdf},
	urldate = {2014-01-16},
	booktitle = {Proceedings of the 16th International Conference on Digital Audio Effects},
	author = {\textbf{Kraft}, $\ast$\textbf{Sebastian} and Lerch, Alexander and Zölzer, Udo},
	year = {2013},
	file = {the tonalness spectrum.pdf:H\:\\Docs\\zotero\\storage\\IDZVSME7\\the tonalness spectrum.pdf:application/pdf}
}

@inproceedings{ness_strategies_2011,
	address = {Hangzhou, China},
	title = {Strategies for Orca Call Retrieval to Support Collaborative Annotation of a Large Archive},
	isbn = {978-1-4577-1434-4},
	url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6093798},
	doi = {10.1109/MMSP.2011.6093798},
	booktitle = {Proceedings of the International Workshop on Multimedia Signal Processing ({MMSP})},
	publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
	author = {Ness, Steven R and Lerch, Alexander and Tzanetakis, George},
	year = {2011},
	file = {2011 - Ness, Lerch, Tzanetakis - Strategies for Orca Call Retrieval to Support Collaborative Annotation of a Large Archive.pdf:H\:\\Docs\\zotero\\storage\\HBV47IGU\\2011 - Ness, Lerch, Tzanetakis - Strategies for Orca Call Retrieval to Support Collaborative Annotation of a Large Archive.pdf:application/pdf}
}

@inproceedings{coler_cmmsd:_2014,
	address = {London, {UK}},
	title = {{CMMSD}: A Data Set for Note-Level Segmentation of Monophonic Music},
	abstract = {A musical data set for note-level segmentation of monophonic music is presented. It contains 36 excerpts from
commercial recordings of monophonic classical western music and features the instrument groups strings,
woodwind and brass. The excerpts are self-contained phrases with a mean length of 17.97 seconds and an
average of 20 notes. All phrases are played in moderate tempo, mostly with significant amounts of expressive
articulation. A manually annotated ground truth splits each item into a sequence of the three states note,
transition and rest. The set is designed as an open source project, aiming at the development and evaluation
of algorithms for segmentation, music performance analysis and feature selection. This paper presents the
process of ground truth labeling and a detailed description of the data set and its properties.},
	booktitle = {Proceedings of the {AES} 53rd International Conference on Semantic Audio},
	publisher = {Audio Engineering Society ({AES})},
	author = {\textbf{Coler}, $\ast$\textbf{Henrik von} and Lerch, Alexander},
	year = {2014},
	file = {AES53-000049.pdf:H\:\\Docs\\zotero\\storage\\2NUMUB6D\\AES53-000049.pdf:application/pdf}
}

@phdthesis{lerch_qualitatsbeurteilung_2001,
	title = {Qualitätsbeurteilung von codierten Audiosignalen mittels eines objektiven Verfahrens Diplomarbeit},
	school = {Technische Universität Berlin},
	author = {Lerch, Alexander},
	year = {2001},
	file = {2001 - Lerch - Qualitätsbeurteilung von codierten Audiosignalen mittels eines objektiven Verfahrens Diplomarbeit.pdf:H\:\\Docs\\zotero\\storage\\D6CFUHH8\\2001 - Lerch - Qualitätsbeurteilung von codierten Audiosignalen mittels eines objektiven Verfahrens Diplomarbeit.pdf:application/pdf}
}

@article{burred_hierarchical_2004,
	title = {Hierarchical Automatic Audio Signal Classification},
	volume = {52},
	abstract = {The design, implementation, and evaluation of a system for automatic audio signal classification is presented. The signals are classified according to audio type, differentiating between three speech classes, 13 musical genres, and background noise. A large number of audio features are evaluated for their suitability in such a classification task, including {MPEG}-7 descriptors and several new features. The selection of the features is carried out systematically with regard to their robustness to noise and bandwidth changes, as well as to their ability to distinguish a given set of audio types. Direct and hierarchical approaches for the feature selection and for the classification are evaluated and compared.},
	number = {7/8},
	journal = {Journal of the Audio Engineering Society ({JAES})},
	author = {\textbf{Burred}, \textbf{Juan José} and Lerch, Alexander},
	year = {2004},
	pages = {724--739},
	publisher = {Audio Engineering Society ({AES})},
	file = {2004 - Burred, Lerch - Hierarchical Automatic Audio Signal Classification.pdf:H\:\\Docs\\zotero\\storage\\WR34F49E\\2004 - Burred, Lerch - Hierarchical Automatic Audio Signal Classification.pdf:application/pdf}
}

@book{lerch_software-based_2009,
	address = {München, Germany},
	title = {Software-Based Extraction of Objective Parameters from Music Performances},
	isbn = {978-3640294961},
	url = {http://opus.kobv.de/tuberlin/volltexte/2008/2067/pdf/lerch\_alexander.pdf},
	abstract = {Different music performances of the same score may significantly differ from each other. It is obvious that not only the composer’s work, the score, defines the listener’s music experience, but that the music performance itself is an integral part of this experience. Music performers use the information contained in the score, but interpret, transform or add to this information. Four parameter classes can be used to describe a performance objectively: tempo and timing, loudness, timbre and pitch. Each class contains a multitude of individual parameters that are at the performers’ disposal to generate a unique physical rendition of musical ideas. The extraction of such objective parameters is one of the difficulties in music performance research. This work presents an approach to the software-based extraction of tempo and timing, loudness and timbre parameters from audio files to provide a tool for the automatic parameter extraction from music performances. The system is applied to extract data from 21 string quartet performances and a detailed analysis of the extracted data is presented. The main contributions of this thesis are the adaptation and development of signal processing approaches to performance parameter extraction and the presentation and discussion of string quartet performances of a movement of Beethoven’s late String Quartet op. 130.},
	publisher = {{GRIN} Verlag},
	author = {Lerch, Alexander},
	year = {2009},
	keywords = {analysis, audio, content, information, music, performance, retrieval},
	file = {2009 - Lerch - Software-Based Extraction of Objective Parameters from Music Performances.pdf:H\:\\Docs\\zotero\\storage\\2GQAJ3PN\\2009 - Lerch - Software-Based Extraction of Objective Parameters from Music Performances.pdf:application/pdf}
}

@inproceedings{yogev_system_2008,
	address = {Leipzig, Germany},
	title = {A System for Automatic Audio Harmonization ({E}in {S}ystem für automatische {A}udio-{H}armonisierung)},
	doi = {10.1.1.148.8391},
	abstract = {A rule-based system for automatic melody harmonization is presented. It models the cognitive process a human arranger undergoes when confronted with the same task, namely: segmenting the melody into phrases, tagging melody notes with harmonic functions, establishing a palette of possible chords for each note, and finding the most agreeable voicing through these chords. The system is designed to be embedded in an audio framework, which synthe- sizes a four-voiced audio output using pitch-shifting techniques. Principles of classical counterpoint as well as common voice-leading conven- tions are utilized by the system. We shall outline the various phases of computa- tion, describe the rules applied in each phase, and present perspectives regarding the stylistic flexibility suggested by the system's design.},
	booktitle = {Proceedings of the {VdT} International Convention (25. Tonmeistertagung)},
	author = {\textbf{Yogev}, \textbf{Noam} and Lerch, Alexander},
	year = {2008},
	keywords = {audio, harmonization},
	file = {2008 - Yogev, Lerch - A System for Automatic Audio Harmonization ( Ein System für automatische Audio-Harmonisierung).pdf:H\:\\Docs\\zotero\\storage\\22F2DX2W\\2008 - Yogev, Lerch - A System for Automatic Audio Harmonization ( Ein System für automatische Audio-Harmonisierung).pdf:application/pdf}
}

@techreport{lerch_evaluation_2005,
	address = {Berlin, Germany},
	type = {White Paper, online (08/2015): \href{http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.60.2182}{citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.60.2182}}, 
	title = {On the Evaluation of Automatic Onset Tracking Systems},
	url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.60.2182},
	abstract = {This paper summarizes the problems, definitions and requirements that are important for the evaluation of onset tracking systems for audio signals in {PCM} format. Different procedures and metrics for evaluation and parametrization are presented and commented. Overall, a complete methodology for the evaluation of automatic onset detection systems is proposed.},
	institution = {zplane.development},
	author = {Lerch, Alexander and \textbf{Klich}, \textbf{Ingmar-Leander}},
	year = {2005},
	annote = {available online (12/2005): \{http://www.zplane.de/Downloads/{OnTheEvaluationOfAutomaticOnsetTrackingSystems}.pdf\}},
	file = {2005 - Lerch, Klich - On the Evaluation of Automatic Onset Tracking Systems.pdf:H\:\\Docs\\zotero\\storage\\MMGQPUSP\\2005 - Lerch, Klich - On the Evaluation of Automatic Onset Tracking Systems.pdf:application/pdf}
}

@incollection{lerch_software-gestutzte_2011,
	address = {Mainz, Germany},
	series = {Klang und Begriff},
	title = {Software-gestützte {M}erkmalsextraktion für die musikalische {A}ufführungs\-ana\-ly\-se ({S}oftware-based Extraction of Descriptors for Music Performance Analysis)},
	isbn = {978-3795707712},
	booktitle = {Gemessene Interpretation --- Computergestützte Aufführungsanalyse im Kreuzverhör der Disziplinen},
	publisher = {Schott},
	author = {Lerch, Alexander},
	editor = {von Loesch, Heinz and Weinzierl, Stefan},
	year = {2011},
	pages = {205--212},
	file = {2011 - Lerch - Software-gestützte Merkmalsextraktion für die musikalische Aufführungsanalyse.pdf:H\:\\Docs\\zotero\\storage\\BPBUZE5A\\2011 - Lerch - Software-gestützte Merkmalsextraktion für die musikalische Aufführungsanalyse.pdf:application/pdf}
}

@incollection{lerch_digitale_2008,
	address = {Berlin, Germany},
	title = {Digitale {A}udiotechnik: {G}rundlagen ({D}igital Audio Technology Fundamentals)},
	isbn = {978-3540343004},
	booktitle = {Handbuch der Audiotechnik},
	publisher = {Springer Verlag},
	author = {Lerch, Alexander and Weinzierl, Stefan},
	editor = {Weinzierl, Stefan},
	year = {2008},
	pages = {785--811},
	file = {2008 - Lerch, Weinzierl - Digitale Audiotechnik Grundlagen.pdf:H\:\\Docs\\zotero\\storage\\Z5G6VIDT\\2008 - Lerch, Weinzierl - Digitale Audiotechnik Grundlagen.pdf:application/pdf}
}

@incollection{lerch_bitratenreduktion_2008,
	address = {Berlin, Germany},
	title = {Bitratenreduktion ({A}udio Source Coding)},
	isbn = {978-3540343004},
	booktitle = {Handbuch der Audiotechnik},
	publisher = {Springer Verlag},
	author = {Lerch, Alexander},
	editor = {Weinzierl, Stefan},
	year = {2008},
	pages = {849--884},
	file = {2008 - Lerch - Bitratenreduktion.pdf:H\:\\Docs\\zotero\\storage\\WIWTN22B\\2008 - Lerch - Bitratenreduktion.pdf:application/pdf}
}

@inproceedings{lerch_feapi:_2005,
	address = {Madrid, Spain},
	title = {{FEAPI}: A Low Level Feature Extraction Plugin {API}},
	url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.59.9079},
	doi = {10.1.1.61.6697},
	booktitle = {Proceedings of 8th International Conference on Digital Audio Effects ({DAFX})},
	author = {Lerch, Alexander and Eisenberg, Gunnar and Tanghe, Koen},
	year = {2005},
	file = {2005 - Lerch, Eisenberg, Tanghe - FEAPI A Low Level Feature Extraction Plugin API.pdf:H\:\\Docs\\zotero\\storage\\3D2X82DC\\2005 - Lerch, Eisenberg, Tanghe - FEAPI A Low Level Feature Extraction Plugin API.pdf:application/pdf}
}

@inproceedings{wiesener_adaptive_2010,
	address = {London, {UK}},
	title = {Adaptive Noise Reduction for Real-time Applications},
	abstract = {We present a new algorithm for real-time noise reduction of audio signals. In order to derive the noise reduction function, the proposed method adaptively estimates the instantaneous noise spectrum from an autoregressive signal model as opposed to the widely-used approach of using a constant noise spectrum fingerprint. In conjunction with the Ephraim and Malah suppression rule a significant reduction of both stationary and non-stationary noise can be obtained. The adaptive algorithm is able to work without user interaction and is capable of real-time processing. Furthermore, quality improvements are easily possible by integration of additional processing blocks such as transient preservation.},
	booktitle = {Proceedings of the 128th Audio Engineering Society Convention (Preprint \#8048)},
	publisher = {Audio Engineering Society ({AES})},
	author = {\textbf{Wiesener}, \textbf{Constantin} and Flohrer, Tim and Lerch, Alexander and Weinzierl, Stefan},
	year = {2010},
	file = {2010 - Wiesener et al. - Adaptive Noise Reduction for Real-time Applications.pdf:H\:\\Docs\\zotero\\storage\\BVXT8RTG\\2010 - Wiesener et al. - Adaptive Noise Reduction for Real-time Applications.pdf:application/pdf}
}

@inproceedings{lerch_requirement_2006,
	address = {Victoria, Canada},
	title = {On the Requirement of Automatic Tuning Frequency Estimation},
	url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.61.6948},
	abstract = {The deviation of the tuning frequency from the standard tuning frequency 440 Hz is evaluated for a database of classical music. It is discussed if and under what circumstances such a deviation may affect the robustness of pitch-based systems for musical content analysis.},
	booktitle = {Proceedings of the 7th International Conference on Music Information Retrieval ({ISMIR})},
	author = {Lerch, Alexander},
	year = {2006},
	keywords = {frequency, tuning},
	publisher = {International Society for Music Information Retrieval ({ISMIR})},
	file = {2006 - Lerch - On the Requirement of Automatic Tuning Frequency Estimation.pdf:H\:\\Docs\\zotero\\storage\\6H9TWH6N\\2006 - Lerch - On the Requirement of Automatic Tuning Frequency Estimation.pdf:application/pdf}
}

@inproceedings{lerch_ansatz_2004,
	address = {Leipzig, Germany},
	title = {Ein {A}nsatz zur automatischen {E}rkennung der {T}onart in {M}usikdateien ({A}n approach to the Automatic Detection of the Musical Key in Audio Files)},
	url = {http://www.mendeley.com/research/ein-ansatz-zur-automatischen-erkennung-der-tonart-musikdateien/},
	abstract = {Es wird ein Verfahren zur automatischen Erkennung der Tonart von Musikdateien vorgestellt. Das Verfahren analysiert mittels einer Filterbank den Tonvorrat des Eingangssignals, der in einem Tonvektor zusammenfasst wird. Dabei sind sowohl mehrstimmige als auch ein- stimmige Eingangssignale zulässig. Mit Hilfe eines Nearest-Neighbour-Classifiers wird anschließ end das wahrscheinlichste Ergebnis für den extrahierten Tonvektor bestimmt. Parallel zur Analyse des Tonvorrats wird die Stimmhöhe des Kammertons detektiert, um eine gleichbleibende Erkennungsrate für Signale unterschiedlicher Stimmhöhe zu gewährleisten.},
	booktitle = {Proceedings of the {VDT} International Audio Convention (23. Tonmeistertagung)},
	author = {Lerch, Alexander},
	year = {2004},
	file = {2004 - Lerch - Ein Ansatz zur automatischen Erkennung der Tonart in Musikdateien.pdf:H\:\\Docs\\zotero\\storage\\WAM57AHA\\2004 - Lerch - Ein Ansatz zur automatischen Erkennung der Tonart in Musikdateien.pdf:application/pdf}
}


@misc{lerch_audio_2014,
	title = {Audio Content Analysis},
	url = {www.AudioContentAnalysis.org},
	urldate = {2014-06-18},
	author = {Lerch, Alexander},
	year = {2014},
	note = {last accessed: 2014-06-18}
}


@incollection{lerch_relationship_????,
	address = {Berlin, Germany},
	title = {The relationship between music technology and the music industry},
	booktitle = {Handbook for Systematic Musicology},
	publisher = {Springer Verlag},
	author = {Lerch, {$\ast$Alexander}},
	editor = {Bader, Rolf},
	year = {in press, expected completion March 15 2018}
}


@inproceedings{lykartsis_analysis_2015,
	address = {Nuremberg, Germany},
	title = {Analysis of {Speech} {Rhythm} for {Language} {Identification} {Based} on {Beat} {Histograms}},
	booktitle = {Proceedings of the {DAGA} ({Jahrestagung} fur {Akustik})},
	author = {\textbf{Lykartsis}, $\ast$\textbf{Athanasios} and Lerch, Alexander and Weinzierl, Stefan},
	year = {2015},
	file = {Paper_DAGA_prefinal_31032015-1.pdf:H\:\\Docs\\zotero\\storage\\6XCRNPPJ\\Paper_DAGA_prefinal_31032015-1.pdf:application/pdf}
}

@inproceedings{gupta_evaluation_2015,
	address = {New Paltz, NJ},
	title = {Evaluation of {State} of the {Art} {Objective} {Source} {Separation} {Measures} in the {Context} of {Singing} {Voice} {Separation}},
	booktitle = {Proceedings of the {IEEE} {Workshop} on {Applications} of {Signal} {Processing} to {Audio} and {Acoustics} ({WASPAA})},
	publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
	author = {\textbf{Gupta}, {$\ast$\textbf{Udit}} and Moore II, Elliot and Lerch, Alexander},
	year = {2015}
}

@inproceedings{lykartsis_rhythm_2015,
	address = {Trondheim, Norway},
	title = {Rhythm {Features} for {Musical} {Genre} {Classification} {Using} {Multiple} {Novelty} {Functions}},
	booktitle = {Proceedings of the {International} {Conference} on {Digital} {Audio} {Effects} ({DAFX})},
	author = {\textbf{Lykartsis}, $\ast$\textbf{Athanasios} and Lerch, Alexander},
	year = {2015}
}

@inproceedings{vartakavi_augmenting_????,
	address = {New Paltz, NJ},
	title = {Augmenting {Audio}-based {Bird} {Species} {Identification} with {Music} {Processing} {Approaches}},
	booktitle = {Proceedings of the {Workshop} on {Applications} of {Signal} {Processing} to {Audio} and {Acoustics} ({WASPAA})},
	publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
	author = {\textbf{Vartakavi}, {$\ast$\textbf{Aneesh}} and Lerch, Alexander},
	year = {under review}
}

@inproceedings{wu_drum_2015a,
	address = {Nice, France},
	title = {Drum {Transcription} using {Partially} {Fixed} {Non}-{Negative} {Matrix} {Factorization}},
	booktitle = {Proceedings of the {European} {Signal} {Processing} {Conference} ({EUSIPCO})},
	publisher = {EURASIP},
	author = {\textbf{Wu}, {$\ast$\textbf{Chih-Wei}} and Lerch, Alexander},
	year = {2015}
}

@inproceedings{obrien_genre-specific_2015,
	address = {Denton, TX},
	title = {Genre-{Specific} {Key} {Profiles}},
	booktitle = {Proceedings of the {International} {Computer} {Music} {Conference} ({ICMC})},
	publisher = {{I}nternational {C}omputer {M}usic {A}ssociation ({ICMA})},
	author = {\textbf{O'Brien}, {$\ast$\textbf{Cian}} and Lerch, Alexander},
	year = {2015}
}


@inproceedings{gupta_evaluation_1???,
	address = {Malaga, Spain},
	title = {Evaluation of {Source} {Separation} {Measures} for {Singing} {Voice} {Separation} through {Pitch} and {Melody} {Extraction}},
	booktitle = {Proceedings of the {International} {Conference} on {Music} {Information} {Retrieval} ({ISMIR})},
	publisher = {International Society for Music Information Retrieval ({ISMIR})},
	author = {\textbf{Gupta}, {$\ast$\textbf{Udit}} and Moore II, Elliot and Lerch, Alexander},
	year = {under review}
}

@inproceedings{liu_unsupervised_????,
	address = {Malaga, Spain},
	title = {An {Unsupervised} {Approach}  for {Cleaning}-{Up} and {Detecting} {Anomalies} in {Musical} {Datasets}},
	booktitle = {Proceedings of the {International} {Conference} on {Music} {Information} {Retrieval} ({ISMIR})},
	publisher = {International Society for Music Information Retrieval ({ISMIR})},
	author = {Liu, {$\ast$Chuanhai} and \textbf{Wu}, \textbf{Chih-Wei} and Lerch, Alexander},
	year = {under review}
}

@inproceedings{lykartsis_beat_2015,
	address = {Malaga, Spain},
	title = {Beat {Histogram} {Features} from {NMF}-{Based} {Novelty} {Functions} for {Music} {Classification}},
	booktitle = {Proceedings of the {International} {Conference} on {Music} {Information} {Retrieval} ({ISMIR})},
	author = {Lykartsis, {$\ast$Athanasios} and \textbf{Wu}, \textbf{Chih-Wei} and Lerch, Alexander},
	publisher = {International Society for Music Information Retrieval ({ISMIR})},
	year = {2015}
}

@inproceedings{wu_drum_2015b,
	address = {Malaga, Spain},
	title = {Drum {Transcription} using {Partially} {Fixed} {Non}-{Negative} {Matrix} {Factorization} {With} {Template} {Adaptation}},
	booktitle = {Proceedings of the {International} {Conference} on {Music} {Information} {Retrieval} ({ISMIR})},
	author = {\textbf{Wu}, {$\ast$\textbf{Chih-Wei}} and Lerch, Alexander},
	publisher = {International Society for Music Information Retrieval ({ISMIR})},
	year = {2015}
}

@inproceedings{zhou_chord_2015,
	address = {Malaga},
	title = {Chord {Detection} {Using} {Deep} {Learning}},
	booktitle = {Proceedings of the {International} {Conference} on {Music} {Information} {Retrieval} ({ISMIR})},
	author = {\textbf{Zhou}, {$\ast$\textbf{Xinquan}} and Lerch, Alexander},
	publisher = {International Society for Music Information Retrieval ({ISMIR})},
	year = {2015}
}


@inproceedings{wu_towards_2016,
	address = {San Francisco},
	title = {Towards the {Objective} {Assessment} of {Music} {Performances}},
	isbn = {1-879346-65-5},
	url = {http://www.icmpc.org/icmpc14/proceedings.html},
	booktitle = {Proceedings of the {International} {Conference} on {Music} {Perception} and {Cognition} ({ICMPC})},
	author = {\textbf{Wu}, $\ast$\textbf{Chih-Wei} and \textbf{Gururani}, \textbf{Siddharth} and \textbf{Laguna}, \textbf{Christopher} and \textbf{Pati}, \textbf{Ashis} and \textbf{Vidwans}, \textbf{Amruta} and Lerch, Alexander},
	year = {2016},
	pages = {99--103},
	file = {gtcmt_icmpc_submission-2.pdf:H\:\\Docs\\zotero\\storage\\CKW7JZ9U\\gtcmt_icmpc_submission-2.pdf:application/pdf;Wu et al_2016_Towards the Objective Assessment of Music Performances.pdf:H\:\\Docs\\zotero\\storage\\QM75CNV5\\Wu et al_2016_Towards the Objective Assessment of Music Performances.pdf:application/pdf}
}

@inproceedings{lu_unsupervised_2016,
	address = {Pisa},
	title = {An {Unsupervised} {Approach} to {Anomaly} {Detection} in {Music} {Datasets}},
	booktitle = {Proceedings of the {ACM} {SIGIR} {Conference} ({SIGIR})},
	publisher = {ACM},
	author = {Lu, $\ast$Yen-Cheng and \textbf{Wu}, \textbf{Chih-Wei} and Lu, Chang-Tien and Lerch, Alexander},
	year = {2016},
	file = {spr092-luA.pdf:H\:\\Docs\\zotero\\storage\\BDX2345H\\spr092-luA.pdf:application/pdf}
}

@inproceedings{wu_drum_2016,
	address = {New York},
	title = {On {Drum} {Playing} {Technique} {Detection} in {Polyphonic} {Mixtures}},
	booktitle = {Proceedings of the {International} {Conference} on {Music} {Information} {Retrieval} ({ISMIR})},
	author = {\textbf{Wu}, $\ast$\textbf{Chih-Wei} and Lerch, Alexander},
	publisher = {International Society for Music Information Retrieval ({ISMIR})},
	year = {2016}
}

@inproceedings{laguna_efficient_2016,
	address = {Los Angeles},
	title = {An {Efficient} {Algorithm} {For} {Clipping} {Detection} {And} {Declipping} {Audio}},
	booktitle = {Proceedings of the 141st {AES} {Convention}},
	publisher = {Audio Engineering Society (AES)},
	author = {\textbf{Laguna}, $\ast$\textbf{Christopher} and Lerch, Alexander},
	year = {2016},
	file = {An Efficient Algorithm For Clipping Detection And Declipping Audio (Camera Ready).pdf:H\:\\Docs\\zotero\\storage\\P45VCX2D\\An Efficient Algorithm For Clipping Detection And Declipping Audio (Camera Ready).pdf:application/pdf}
}

@inproceedings{winters_automatic_2016,
	address = {New York},
	title = {Automatic {Practice} {Logging}: {Introduction}, {Dataset} \& {Preliminary} {Study}},
	abstract = {Musicians spend countless hours practicing their instru-
ments. To document and organize this time, musicians com-
monly use practice charts to log their practice. However,
manual techniques require time, dedication, and experience
to master, are prone to fallacy and omission, and ultimately
can not describe the subtle variations in each repetition.
This paper presents an alternative: by analyzing and clas-
sifying the audio recorded while practicing, logging could
occur automatically, with levels of detail, accuracy, and ease
that would not be possible otherwise. Towards this goal,
we introduce the problem of Automatic Practice Logging
(APL), including a discussion of the benefits and unique
challenges it raises. We then describe a new dataset of over
600 annotated recordings of solo piano practice, which can
be used to design and evaluate APL systems. After fram-
ing our approach to the problem, we present an algorithm
designed to align short segments of practice audio with
reference recordings using pitch chroma and dynamic time
warping.},
	booktitle = {Proceedings of the {International} {Conference} on {Music} {Information} {Retrieval} ({ISMIR})},
	author = {\textbf{Winters}, $\ast$\textbf{R Michael} and \textbf{Gururani}, \textbf{Siddharth} and Lerch, Alexander},
	year = {2016},
	publisher = {International Society for Music Information Retrieval ({ISMIR})},
	file = {automatic-practice-logging.pdf:H\:\\Docs\\zotero\\storage\\BG9MK2QG\\automatic-practice-logging.pdf:application/pdf}
}

@inproceedings{lu_automatic_2016,
	address = {New York},
	series = {{ISMIR}},
	title = {Automatic {Outlier} {Detection} in {Music} {Genre} {Datasets}},
	booktitle = {Proceedings of the {International} {Conference} on {Music} {Information} {Retrieval} ({ISMIR})},
	publisher = {International Society for Music Information Retrieval ({ISMIR})},
	author = {Lu, $\ast$Yen-Cheng and \textbf{Wu}, \textbf{Chih-Wei} and Lu, Chang-Tien and Lerch, Alexander},
	year = {2016},
	keywords = {anomaly detection, data clean-up, music genre retrieval, music information retrieval},
	file = {Lu et al_2016_Automatic Outlier Detection in Music Genre Datasets.pdf:H\:\\Docs\\zotero\\storage\\848ZE7II\\Lu et al_2016_Automatic Outlier Detection in Music Genre Datasets.pdf:application/pdf}
}

@inproceedings{pati_dataset_2017,
	address = {Erlangen},
	title = {A {Dataset} and {Method} for {Guitar} {Solo} {Detection} in {Rock} {Music}},
	booktitle = {Proceedings of the {AES} {Conference} on {Semantic} {Audio}},
	publisher = {Audio Engineering Society (AES)},
	author = {\textbf{Pati}, $\ast$\textbf{Kumar Ashis} and Lerch, Alexander},
	year = {2017}
}

@inproceedings{vidwans_objective_2017,
	address = {Erlangen},
	title = {Objective descriptors for the assessment of student music performances},
	booktitle = {Proceedings of the {AES} {Conference} on {Semantic} {Audio}},
	publisher = {Audio Engineering Society (AES)},
	author = {\textbf{Vidwans}, $\ast$\textbf{Amruta} and \textbf{Gururani}, \textbf{Siddharth} and \textbf{Wu}, \textbf{Chih-Wei} and \textbf{Subramanian}, \textbf{Vinod} and \textbf{Swaminathan}, \textbf{Rupak} \textbf{Vignesh} and Lerch, Alexander},
	year = {2017}
}

@inproceedings{gururani_automatic_2017,
	address = {Suzhou},
	title = {Automatic {Sample} {Detection} in {Polyphonic} {Music}},
	url = {http://www.musicinformatics.gatech.edu/wp-content_nondefault/uploads/2016/07/Winters-et-al_2016_Automatic-Practice-Logging.pdf},
	abstract = {The term `sampling' refers to the usage of snippets or loops from existing songs or sample libraries in new songs, mashups, or other music productions. The ability to automatically detect sampling in music is, for instance, beneficial for studies tracking artist influences geographically and temporally. We present a method based on Non-negative Matrix Factorization (NMF) and Dynamic Time Warping (DTW) for the automatic detection of a sample in a pool of songs. The method comprises of two processing steps: first, the DTW alignment path between NMF activations of a song and query sample is computed. Second, features are extracted from this path and used to train a Random Forest classifier to detect the presence of the sample. The method is able to identify samples that are pitch shifted and/or time stretched with approximately 63\% F-measure. We evaluate this method against a new publicly available dataset of real-world sample and song pairs.},
	booktitle = {Proceedings of the {International} {Society} for {Music} {Information} {Retrieval} {Conference} ({ISMIR})},
	publisher = {International Society for Music Information Retrieval ({ISMIR})},
	author = {\textbf{Gururani}, $\ast$\textbf{Siddharth} and Lerch, Alexander},
	year = {2017},
	file = {Gururani_Lerch_2017_Automatic Sample Detection in Polyphonic Music.pdf:H\:\\Docs\\zotero\\storage\\UD8IJKI7\\Gururani_Lerch_2017_Automatic Sample Detection in Polyphonic Music.pdf:application/pdf}
}

@inproceedings{wu_automatic_2017,
	address = {Suzhou},
	title = {Automatic drum transcription using the student-teacher learning paradigm with unlabeled music data},
	url = {http://www.musicinformatics.gatech.edu/wp-content_nondefault/uploads/2016/07/Wu_Lerch_2016_On-Drum-Playing-Technique-Detection-in-Polyphonic-Mixtures.pdf},
	abstract = {Automatic drum transcription is a sub-task of automatic music transcription that converts drum-related audio events into musical notation. While noticeable progress has been made in the past by combining pattern recognition methods with audio signal processing techniques, the major limitation of many state-of-the-art systems still originates from the difficulty of obtaining a meaningful amount of annotated data to support the data-driven algorithms. In this work, we address the challenge of insufficiently labeled data by exploring the possibility of utilizing unlabeled music data from online resources. Specifically, a student neural network is trained using the labels generated from multiple teacher systems. The performance of the model is evaluated on a publicly available dataset. The results show the general viability of using unlabeled music data to improve the performance of drum transcription systems.},
	booktitle = {Proceedings of the {International} {Society} for {Music} {Information} {Retrieval} {Conference} ({ISMIR})},
	publisher = {International Society for Music Information Retrieval ({ISMIR})},
	author = {\textbf{Wu}, $\ast$\textbf{Chih-Wei} and Lerch, Alexander},
	year = {2017},
	file = {Wu_Lerch_2017_Automatic drum transcription using the student-teacher learning paradigm with.pdf:H\:\\Docs\\zotero\\storage\\T5WQFKDS\\Wu_Lerch_2017_Automatic drum transcription using the student-teacher learning paradigm with.pdf:application/pdf}
}

@inproceedings{wu_mdb_2017,
	address = {Suzhou},
	title = {{MDB} {Drums} --- {An} {Annotated} {Subset} of {MedleyDB} for {Automatic} {Drum} {Transcription}},
	url = {http://www.musicinformatics.gatech.edu/wp-content_nondefault/uploads/2017/10/Wu-et-al_2017_MDB-Drums-An-Annotated-Subset-of-MedleyDB-for-Automatic-Drum-Transcription.pdf},
	abstract = {In this paper we present MDB Drums, a new dataset for automatic drum transcription (ADT) tasks. This dataset is built on top of the MusicDelta subset of the MedleyDB dataset, taking advantage of real-world recordings in multi-track format. The dataset is comprised of a variety of genres, providing a balanced pool for developing and evaluating ADT models with respect to various musical styles.
To reduce the cost of the labor-intensive process of manual annotation, a semi-automatic process was utilised in both the annotation and quality control processes. The pre sented dataset consists of 23 tracks with a total of 7994 onsets. These onsets are divided into 6 classes based on drum instruments or 21 subclasses based on playing techniques. Every track consists of a drum-only track as well
as multiple accompanied tracks, enabling audio files containing different combinations of instruments to be used in the ADT evaluation process.},
	booktitle = {Late {Breaking} {Demo} ({Extended} {Abstract}), {Proceedings} of the {International} {Society} for {Music} {Information} {Retrieval} {Conference} ({ISMIR})},
	publisher = {International Society for Music Information Retrieval (ISMIR)},
	author = {\textbf{Wu}, $\ast$\textbf{Chih-Wei} and Southall, Carl and Lerch, Alexander and Hockman, Jason A},
	year = {2017},
	file = {Wu et al_2017_MDB Drums --- An Annotated Subset of MedleyDB for Automatic Drum Transcription.pdf:H\:\\Docs\\zotero\\storage\\BEQV2VGE\\Wu et al_2017_MDB Drums --- An Annotated Subset of MedleyDB for Automatic Drum Transcription.pdf:application/pdf}
}

@inproceedings{zhiqian_chen_learning_2017,
	address = {New Orleans},
	title = {Learning to {Fuse} {Music} {Genres} with {Generative} {Adversarial} {Dual} {Learning}},
	booktitle = {Proceedings of the {International} {Conference} on {Data} {Mining} ({ICDM})},
	publisher = {Institute of Electrical and Electronics Engineers (IEEE)},
	author = {Chen, $\ast$Zhiqian  and \textbf{Wu}, \textbf{Chih-Wei} and Lu, Yen-Cheng and Lerch, Alexander and Lu, Chang-Tien},
	year = {2017}
}
@article{wang_technology_nodate,
	title = {On technology in vocal education},
	issn = {17527066},
	journal = {Journal of Music, Technology and Education},
	author = {\textbf{Wang}, $\ast$\textbf{Jonathan} and Hsu, Timothy and Lerch, Alexander},
	year = {submitted 2017/02}
}

@article{wu_overview_nodate,
	title = {An {Overview} of {Automatic} {Drum} {Transcription}},
	journal = {Transactions on Audio, Speech and Language Processing},
	author = {\textbf{Wu}, $\ast$\textbf{Chih-Wei} and Dittmar, Christian and Southall, Carl and Vogl, Richard and Widmer, Gerhard and Hockman, Jason A and M{\"u}ller, Meinard and Lerch, Alexander},
	year = {submitted 2017/11}
}


